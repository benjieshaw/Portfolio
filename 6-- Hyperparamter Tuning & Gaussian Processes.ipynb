{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2429c219-7f54-44ab-a2f4-22f7c2b68833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc17571-18f8-402f-a05d-61684cbea109",
   "metadata": {},
   "source": [
    "# Import the model & train/test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c16bc4c-bbd1-4b37-ab50-8c87d58e3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('gbr_x3_model.pkl')\n",
    "train_X3 = pd.read_csv('X_train_3.csv')\n",
    "test_X3 = pd.read_csv('X_test_3.csv')\n",
    "train_y3 = pd.read_csv('y_train_3.csv')\n",
    "test_y3 = pd.read_csv('y_test_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4435a5-6fbd-46e8-a29f-d22491b2685b",
   "metadata": {},
   "source": [
    "All of the imported DFs have the mysterious 'Unnamed: 0' column. Let's drop that from each of the DFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6a320b-a83f-4bb3-b65a-7424f3c06f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X3 = train_X3.drop(columns='Unnamed: 0')\n",
    "test_X3 = test_X3.drop(columns='Unnamed: 0')\n",
    "train_y3 = train_y3.drop(columns='Unnamed: 0')\n",
    "test_y3 = test_y3.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5f633-2420-4f4a-8762-3a3bf0fbcf01",
   "metadata": {},
   "source": [
    "The y frames need to be changed to 1D arrays for GridSearch to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a01fa5c-f719-4c50-80e7-0acce1b0393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y3 = train_y3.values.ravel()\n",
    "test_y3 = test_y3.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac423320-58b9-48a3-9fe0-e970cc9ca443",
   "metadata": {},
   "source": [
    "# Tune the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112f7b63-bb14-4701-833a-0451ad9afedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best MSE Score: -1.0416675882872979\n"
     ]
    }
   ],
   "source": [
    "#Define dictionary with possible parameters\n",
    "params = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [1.0, 'sqrt', 'log2']}\n",
    "\n",
    "#Perform GridSearch\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(train_X3, train_y3)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb13a6-ff82-47d6-8a96-9503b52fe6c9",
   "metadata": {},
   "source": [
    "Since I specified neg_mean_squared_error as the scoring parameter, this MSE is actually 1.1252. That score is actually higher than the non-optimized value from the previous notebook (1.029). That being the case, I will perform another round of optimization to try to improve the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41569f9-812c-42b7-8aee-70044c5aa016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Best MSE Score: -1.1268130595402268\n"
     ]
    }
   ],
   "source": [
    "#Define dictionary with possible parameters\n",
    "#n_estimators was found to be optimal at the default value, so it will be omitted below\n",
    "#since default values perform better, this search will allow max_features to default\n",
    "params_2 = {\n",
    "    'learning_rate': [0.01, 0.005, 0.0001],\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_split': [10, 25, 50],\n",
    "    'min_samples_leaf': [4, 10, 25]}\n",
    "\n",
    "#Perform GridSearch\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params_2,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1)\n",
    "\n",
    "grid_search_2.fit(train_X3, train_y3)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_2.best_params_)\n",
    "print(\"Best MSE Score:\", grid_search_2.best_score_)\n",
    "\n",
    "best_model_2 = grid_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f5ce2-2dfd-429e-b3b0-4b7cea9c6725",
   "metadata": {},
   "source": [
    "The MSE is still not better than the default value, but it's closer. I will tune hyperparameters once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f38a938-d843-4c08-aebb-f5c0fc7729a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 50}\n",
      "Best MSE Score: -1.1511442926262707\n"
     ]
    }
   ],
   "source": [
    "#Define dictionary with possible parameters\n",
    "#n_estimators and max_features are defaulted\n",
    "#learning_rate and min_samples_leaf were the same across both tunings, so we will specify those values but not further tune them\n",
    "\n",
    "params_3 = {\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [1, 2, 3, 4],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [50, 75, 100]}\n",
    "\n",
    "#Perform GridSearch\n",
    "grid_search_3 = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params_3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1)\n",
    "\n",
    "grid_search_3.fit(train_X3, train_y3)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_3.best_params_)\n",
    "print(\"Best MSE Score:\", grid_search_3.best_score_)\n",
    "\n",
    "best_model_3 = grid_search_3.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbed4a-c81e-49d5-8872-bf1938af6484",
   "metadata": {},
   "source": [
    "This tuning resulted in the same set of hyperparameters for the model as the previous round. Hyperparameter tuning is complete.\n",
    "\n",
    "The MSE is still not as low as the generic model, but it is quite close, so I will keep it to make predictions below.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3346a184-b5cb-423d-9535-84091595e2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=4, min_samples_leaf=4,\n",
       "                          min_samples_split=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=4, min_samples_leaf=4,\n",
       "                          min_samples_split=50, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=4, min_samples_leaf=4,\n",
       "                          min_samples_split=50, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update the model with the optimized hyperparameters\n",
    "hyperparameters = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 50}\n",
    "\n",
    "#Update the hyperparameters\n",
    "model.set_params(**hyperparameters)\n",
    "\n",
    "#Fit the model to the training data to prepare for Gaussian Processes\n",
    "model.fit(train_X3, train_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a8c01-a4fb-499a-91ad-8a5b90089f2a",
   "metadata": {},
   "source": [
    "## Make Predictions with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991626b8-ca25-4c5b-94c2-c538d82f9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on training and test set\n",
    "train_preds = model.predict(train_X3)\n",
    "test_preds = model.predict(test_X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed664d76-fb99-486b-9be6-d9f45716c741",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cdeff32-5d7c-47c3-a8f9-345e5869fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 16.7918, Lower Bound: 14.7501, Upper Bound: 18.8334\n",
      "Prediction: 16.8315, Lower Bound: 14.7899, Upper Bound: 18.8732\n",
      "Prediction: 17.0356, Lower Bound: 14.9939, Upper Bound: 19.0773\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 16.7490, Lower Bound: 14.7073, Upper Bound: 18.7907\n",
      "Prediction: 16.7780, Lower Bound: 14.7364, Upper Bound: 18.8197\n",
      "Prediction: 16.6711, Lower Bound: 14.6295, Upper Bound: 18.7128\n",
      "Prediction: 16.9490, Lower Bound: 14.9074, Upper Bound: 18.9907\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.9230, Lower Bound: 14.8813, Upper Bound: 18.9647\n",
      "Prediction: 16.9771, Lower Bound: 14.9355, Upper Bound: 19.0188\n",
      "Prediction: 16.9230, Lower Bound: 14.8813, Upper Bound: 18.9647\n",
      "Prediction: 17.0179, Lower Bound: 14.9762, Upper Bound: 19.0596\n",
      "Prediction: 18.9849, Lower Bound: 18.7898, Upper Bound: 19.1800\n",
      "Prediction: 17.0354, Lower Bound: 15.0599, Upper Bound: 19.0108\n",
      "Prediction: 16.5051, Lower Bound: 16.3100, Upper Bound: 16.7002\n",
      "Prediction: 16.9230, Lower Bound: 14.8813, Upper Bound: 18.9647\n",
      "Prediction: 16.8422, Lower Bound: 14.8005, Upper Bound: 18.8839\n",
      "Prediction: 16.9445, Lower Bound: 14.9029, Upper Bound: 18.9862\n",
      "Prediction: 16.8275, Lower Bound: 14.7859, Upper Bound: 18.8691\n",
      "Prediction: 16.8011, Lower Bound: 16.6060, Upper Bound: 16.9962\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9739, Lower Bound: 14.9322, Upper Bound: 19.0156\n",
      "Prediction: 16.8073, Lower Bound: 14.7656, Upper Bound: 18.8490\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.7804, Lower Bound: 14.7387, Upper Bound: 18.8221\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.7950, Lower Bound: 14.7534, Upper Bound: 18.8367\n",
      "Prediction: 16.7525, Lower Bound: 14.7108, Upper Bound: 18.7942\n",
      "Prediction: 16.8241, Lower Bound: 14.7829, Upper Bound: 18.8654\n",
      "Prediction: 16.8219, Lower Bound: 14.7802, Upper Bound: 18.8635\n",
      "Prediction: 17.0394, Lower Bound: 14.9977, Upper Bound: 19.0810\n",
      "Prediction: 16.9973, Lower Bound: 14.9557, Upper Bound: 19.0388\n",
      "Prediction: 16.9274, Lower Bound: 14.8857, Upper Bound: 18.9690\n",
      "Prediction: 17.2960, Lower Bound: 15.6269, Upper Bound: 18.9650\n",
      "Prediction: 17.1114, Lower Bound: 15.0697, Upper Bound: 19.1531\n",
      "Prediction: 16.6306, Lower Bound: 14.5890, Upper Bound: 18.6723\n",
      "Prediction: 16.8539, Lower Bound: 14.8122, Upper Bound: 18.8956\n",
      "Prediction: 16.5670, Lower Bound: 14.7247, Upper Bound: 18.4092\n",
      "Prediction: 16.9626, Lower Bound: 14.9540, Upper Bound: 18.9713\n",
      "Prediction: 17.0394, Lower Bound: 14.9977, Upper Bound: 19.0810\n",
      "Prediction: 17.3886, Lower Bound: 15.3469, Upper Bound: 19.4302\n",
      "Prediction: 16.9452, Lower Bound: 14.9036, Upper Bound: 18.9869\n",
      "Prediction: 17.0326, Lower Bound: 15.1819, Upper Bound: 18.8833\n",
      "Prediction: 17.4631, Lower Bound: 15.4214, Upper Bound: 19.5048\n",
      "Prediction: 16.9283, Lower Bound: 14.8867, Upper Bound: 18.9700\n",
      "Prediction: 16.8744, Lower Bound: 14.8327, Upper Bound: 18.9161\n",
      "Prediction: 16.5919, Lower Bound: 14.5502, Upper Bound: 18.6336\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.9660, Lower Bound: 14.9245, Upper Bound: 19.0075\n",
      "Prediction: 17.1004, Lower Bound: 15.0646, Upper Bound: 19.1362\n",
      "Prediction: 17.0090, Lower Bound: 15.1874, Upper Bound: 18.8305\n",
      "Prediction: 16.7168, Lower Bound: 14.6751, Upper Bound: 18.7585\n",
      "Prediction: 18.9810, Lower Bound: 18.7859, Upper Bound: 19.1761\n",
      "Prediction: 16.8822, Lower Bound: 14.8405, Upper Bound: 18.9239\n",
      "Prediction: 16.8090, Lower Bound: 14.7673, Upper Bound: 18.8507\n",
      "Prediction: 16.7722, Lower Bound: 14.7305, Upper Bound: 18.8139\n",
      "Prediction: 16.9448, Lower Bound: 14.9031, Upper Bound: 18.9864\n",
      "Prediction: 16.9970, Lower Bound: 14.9553, Upper Bound: 19.0386\n",
      "Prediction: 16.9555, Lower Bound: 14.9138, Upper Bound: 18.9972\n",
      "Prediction: 17.0560, Lower Bound: 15.0144, Upper Bound: 19.0977\n",
      "Prediction: 16.9920, Lower Bound: 14.9503, Upper Bound: 19.0337\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.4172, Lower Bound: 15.4024, Upper Bound: 19.4320\n",
      "Prediction: 17.6925, Lower Bound: 15.6509, Upper Bound: 19.7342\n",
      "Prediction: 16.7804, Lower Bound: 14.7387, Upper Bound: 18.8221\n",
      "Prediction: 17.0540, Lower Bound: 15.0123, Upper Bound: 19.0957\n",
      "Prediction: 17.4947, Lower Bound: 17.2996, Upper Bound: 17.6898\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 17.0606, Lower Bound: 15.0460, Upper Bound: 19.0753\n",
      "Prediction: 16.6666, Lower Bound: 14.6249, Upper Bound: 18.7083\n",
      "Prediction: 16.8089, Lower Bound: 14.7673, Upper Bound: 18.8506\n",
      "Prediction: 16.9731, Lower Bound: 14.9314, Upper Bound: 19.0148\n",
      "Prediction: 17.0022, Lower Bound: 14.9605, Upper Bound: 19.0439\n",
      "Prediction: 16.9413, Lower Bound: 14.8997, Upper Bound: 18.9830\n",
      "Prediction: 16.9771, Lower Bound: 14.9355, Upper Bound: 19.0188\n",
      "Prediction: 17.0280, Lower Bound: 14.9922, Upper Bound: 19.0637\n",
      "Prediction: 16.7441, Lower Bound: 14.7025, Upper Bound: 18.7858\n",
      "Prediction: 16.7409, Lower Bound: 14.6992, Upper Bound: 18.7826\n",
      "Prediction: 16.7203, Lower Bound: 14.6786, Upper Bound: 18.7620\n",
      "Prediction: 16.7403, Lower Bound: 14.6986, Upper Bound: 18.7820\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 16.6443, Lower Bound: 14.6026, Upper Bound: 18.6860\n",
      "Prediction: 16.5995, Lower Bound: 14.5578, Upper Bound: 18.6412\n",
      "Prediction: 16.7284, Lower Bound: 14.6867, Upper Bound: 18.7701\n",
      "Prediction: 16.7860, Lower Bound: 14.7712, Upper Bound: 18.8008\n",
      "Prediction: 16.6288, Lower Bound: 14.5873, Upper Bound: 18.6703\n",
      "Prediction: 16.9976, Lower Bound: 15.1321, Upper Bound: 18.8630\n",
      "Prediction: 17.0022, Lower Bound: 14.9605, Upper Bound: 19.0439\n",
      "Prediction: 16.7490, Lower Bound: 14.7073, Upper Bound: 18.7907\n",
      "Prediction: 16.7634, Lower Bound: 14.7217, Upper Bound: 18.8051\n",
      "Prediction: 17.4631, Lower Bound: 15.4215, Upper Bound: 19.5048\n",
      "Prediction: 16.8768, Lower Bound: 14.8351, Upper Bound: 18.9184\n",
      "Prediction: 16.9862, Lower Bound: 14.9445, Upper Bound: 19.0279\n",
      "Prediction: 16.9450, Lower Bound: 14.9033, Upper Bound: 18.9866\n",
      "Prediction: 16.7604, Lower Bound: 14.7187, Upper Bound: 18.8021\n",
      "Prediction: 16.8506, Lower Bound: 14.8089, Upper Bound: 18.8923\n",
      "Prediction: 16.7168, Lower Bound: 14.6751, Upper Bound: 18.7585\n",
      "Prediction: 16.8822, Lower Bound: 14.8405, Upper Bound: 18.9239\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8613\n",
      "Prediction: 16.7804, Lower Bound: 14.7387, Upper Bound: 18.8221\n",
      "Prediction: 16.8962, Lower Bound: 14.8545, Upper Bound: 18.9378\n",
      "Prediction: 16.7490, Lower Bound: 14.7073, Upper Bound: 18.7907\n",
      "Prediction: 16.8528, Lower Bound: 14.8112, Upper Bound: 18.8944\n",
      "Prediction: 16.9059, Lower Bound: 14.8642, Upper Bound: 18.9475\n",
      "Prediction: 17.0151, Lower Bound: 15.1272, Upper Bound: 18.9031\n",
      "Prediction: 16.6842, Lower Bound: 14.6425, Upper Bound: 18.7259\n",
      "Prediction: 17.0997, Lower Bound: 15.0911, Upper Bound: 19.1084\n",
      "Prediction: 16.9035, Lower Bound: 16.7087, Upper Bound: 17.0983\n",
      "Prediction: 16.6015, Lower Bound: 16.4064, Upper Bound: 16.7966\n",
      "Prediction: 16.8141, Lower Bound: 14.7724, Upper Bound: 18.8558\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.9081, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 16.8249, Lower Bound: 14.7832, Upper Bound: 18.8666\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 17.0540, Lower Bound: 15.0123, Upper Bound: 19.0957\n",
      "Prediction: 16.9650, Lower Bound: 14.9233, Upper Bound: 19.0067\n",
      "Prediction: 17.0353, Lower Bound: 14.9936, Upper Bound: 19.0770\n",
      "Prediction: 16.7569, Lower Bound: 14.7370, Upper Bound: 18.7768\n",
      "Prediction: 16.9080, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 16.9017, Lower Bound: 14.8600, Upper Bound: 18.9433\n",
      "Prediction: 17.0499, Lower Bound: 15.0082, Upper Bound: 19.0916\n",
      "Prediction: 16.9972, Lower Bound: 14.9556, Upper Bound: 19.0389\n",
      "Prediction: 17.0392, Lower Bound: 14.9975, Upper Bound: 19.0809\n",
      "Prediction: 16.9987, Lower Bound: 16.8036, Upper Bound: 17.1938\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8511, Lower Bound: 14.8095, Upper Bound: 18.8928\n",
      "Prediction: 16.9044, Lower Bound: 14.8627, Upper Bound: 18.9460\n",
      "Prediction: 16.6842, Lower Bound: 14.6425, Upper Bound: 18.7259\n",
      "Prediction: 16.9995, Lower Bound: 16.8044, Upper Bound: 17.1946\n",
      "Prediction: 16.9315, Lower Bound: 14.8898, Upper Bound: 18.9732\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.8768, Lower Bound: 14.8351, Upper Bound: 18.9184\n",
      "Prediction: 16.7207, Lower Bound: 14.6790, Upper Bound: 18.7623\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9985, Lower Bound: 14.9568, Upper Bound: 19.0402\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.5041, Lower Bound: 16.3090, Upper Bound: 16.6992\n",
      "Prediction: 16.7510, Lower Bound: 14.7093, Upper Bound: 18.7927\n",
      "Prediction: 17.0402, Lower Bound: 15.2013, Upper Bound: 18.8791\n",
      "Prediction: 16.9681, Lower Bound: 15.1174, Upper Bound: 18.8188\n",
      "Prediction: 16.7207, Lower Bound: 14.6790, Upper Bound: 18.7623\n",
      "Prediction: 16.8545, Lower Bound: 14.8128, Upper Bound: 18.8962\n",
      "Prediction: 16.9080, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 16.9156, Lower Bound: 14.8739, Upper Bound: 18.9573\n",
      "Prediction: 16.9017, Lower Bound: 14.8600, Upper Bound: 18.9433\n",
      "Prediction: 16.8607, Lower Bound: 14.8190, Upper Bound: 18.9024\n",
      "Prediction: 16.8250, Lower Bound: 14.7833, Upper Bound: 18.8667\n",
      "Prediction: 16.9991, Lower Bound: 14.9915, Upper Bound: 19.0067\n",
      "Prediction: 16.9648, Lower Bound: 14.9231, Upper Bound: 19.0064\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9085, Lower Bound: 14.8668, Upper Bound: 18.9501\n",
      "Prediction: 17.8918, Lower Bound: 17.6967, Upper Bound: 18.0869\n",
      "Prediction: 16.9552, Lower Bound: 14.9135, Upper Bound: 18.9969\n",
      "Prediction: 16.8398, Lower Bound: 14.7981, Upper Bound: 18.8815\n",
      "Prediction: 16.7301, Lower Bound: 14.6885, Upper Bound: 18.7718\n",
      "Prediction: 16.9275, Lower Bound: 14.8859, Upper Bound: 18.9691\n",
      "Prediction: 16.7382, Lower Bound: 14.6965, Upper Bound: 18.7799\n",
      "Prediction: 16.9553, Lower Bound: 14.9137, Upper Bound: 18.9970\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.7581, Lower Bound: 14.7164, Upper Bound: 18.7998\n",
      "Prediction: 17.3385, Lower Bound: 15.4934, Upper Bound: 19.1835\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 16.8694, Lower Bound: 14.8277, Upper Bound: 18.9110\n",
      "Prediction: 16.8215, Lower Bound: 15.0148, Upper Bound: 18.6282\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.8656, Lower Bound: 14.8569, Upper Bound: 18.8742\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.7488, Lower Bound: 14.7071, Upper Bound: 18.7905\n",
      "Prediction: 16.7439, Lower Bound: 14.7022, Upper Bound: 18.7856\n",
      "Prediction: 17.0789, Lower Bound: 15.2088, Upper Bound: 18.9490\n",
      "Prediction: 16.8313, Lower Bound: 14.7897, Upper Bound: 18.8730\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9717, Lower Bound: 14.9305, Upper Bound: 19.0129\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.1735, Lower Bound: 14.2925, Upper Bound: 18.0546\n",
      "Prediction: 16.8335, Lower Bound: 14.7918, Upper Bound: 18.8752\n",
      "Prediction: 16.9626, Lower Bound: 14.9540, Upper Bound: 18.9713\n",
      "Prediction: 16.9080, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 17.0197, Lower Bound: 14.9781, Upper Bound: 19.0614\n",
      "Prediction: 17.4954, Lower Bound: 17.3003, Upper Bound: 17.6905\n",
      "Prediction: 17.0518, Lower Bound: 15.0101, Upper Bound: 19.0934\n",
      "Prediction: 16.9920, Lower Bound: 14.9503, Upper Bound: 19.0337\n",
      "Prediction: 17.0994, Lower Bound: 16.9043, Upper Bound: 17.2945\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8250, Lower Bound: 14.7833, Upper Bound: 18.8667\n",
      "Prediction: 16.7290, Lower Bound: 14.6873, Upper Bound: 18.7707\n",
      "Prediction: 16.5542, Lower Bound: 14.5616, Upper Bound: 18.5468\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.6997, Lower Bound: 14.6581, Upper Bound: 18.7414\n",
      "Prediction: 16.8253, Lower Bound: 14.8080, Upper Bound: 18.8426\n",
      "Prediction: 16.9258, Lower Bound: 14.8843, Upper Bound: 18.9674\n",
      "Prediction: 16.7528, Lower Bound: 14.7112, Upper Bound: 18.7945\n",
      "Prediction: 16.8574, Lower Bound: 14.8157, Upper Bound: 18.8991\n",
      "Prediction: 17.5896, Lower Bound: 15.5479, Upper Bound: 19.6313\n",
      "Prediction: 16.8071, Lower Bound: 14.7654, Upper Bound: 18.8488\n",
      "Prediction: 16.4724, Lower Bound: 14.5844, Upper Bound: 18.3604\n",
      "Prediction: 16.9803, Lower Bound: 14.9386, Upper Bound: 19.0220\n",
      "Prediction: 16.7671, Lower Bound: 14.7255, Upper Bound: 18.8088\n",
      "Prediction: 17.4172, Lower Bound: 15.4024, Upper Bound: 19.4320\n",
      "Prediction: 16.8608, Lower Bound: 14.8191, Upper Bound: 18.9025\n",
      "Prediction: 16.7793, Lower Bound: 14.8913, Upper Bound: 18.6673\n",
      "Prediction: 16.9020, Lower Bound: 14.8603, Upper Bound: 18.9437\n",
      "Prediction: 16.9984, Lower Bound: 16.8033, Upper Bound: 17.1935\n",
      "Prediction: 16.9691, Lower Bound: 14.9285, Upper Bound: 19.0098\n",
      "Prediction: 16.8459, Lower Bound: 14.8042, Upper Bound: 18.8876\n",
      "Prediction: 16.8189, Lower Bound: 14.7773, Upper Bound: 18.8606\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9844, Lower Bound: 14.9427, Upper Bound: 19.0260\n",
      "Prediction: 16.5800, Lower Bound: 14.7106, Upper Bound: 18.4493\n",
      "Prediction: 16.9763, Lower Bound: 14.9346, Upper Bound: 19.0179\n",
      "Prediction: 16.8489, Lower Bound: 14.8072, Upper Bound: 18.8906\n",
      "Prediction: 16.2057, Lower Bound: 16.0106, Upper Bound: 16.4008\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.7013, Lower Bound: 14.6596, Upper Bound: 18.7430\n",
      "Prediction: 16.8176, Lower Bound: 14.7759, Upper Bound: 18.8593\n",
      "Prediction: 16.9543, Lower Bound: 14.9126, Upper Bound: 18.9960\n",
      "Prediction: 16.8202, Lower Bound: 14.7785, Upper Bound: 18.8619\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8752, Lower Bound: 14.8335, Upper Bound: 18.9169\n",
      "Prediction: 16.4941, Lower Bound: 14.4524, Upper Bound: 18.5357\n",
      "Prediction: 16.8739, Lower Bound: 14.8323, Upper Bound: 18.9155\n",
      "Prediction: 17.3624, Lower Bound: 15.3207, Upper Bound: 19.4041\n",
      "Prediction: 16.6976, Lower Bound: 14.6559, Upper Bound: 18.7393\n",
      "Prediction: 16.9843, Lower Bound: 14.9427, Upper Bound: 19.0258\n",
      "Prediction: 17.4192, Lower Bound: 15.5685, Upper Bound: 19.2699\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 15.1178, Lower Bound: 14.9227, Upper Bound: 15.3129\n",
      "Prediction: 16.7524, Lower Bound: 14.7108, Upper Bound: 18.7941\n",
      "Prediction: 17.0654, Lower Bound: 15.0237, Upper Bound: 19.1071\n",
      "Prediction: 16.8071, Lower Bound: 14.7654, Upper Bound: 18.8488\n",
      "Prediction: 16.9080, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 16.7776, Lower Bound: 14.7391, Upper Bound: 18.8160\n",
      "Prediction: 16.8336, Lower Bound: 14.7919, Upper Bound: 18.8753\n",
      "Prediction: 16.9274, Lower Bound: 14.8857, Upper Bound: 18.9690\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.8791, Lower Bound: 14.8374, Upper Bound: 18.9208\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 17.0394, Lower Bound: 14.9977, Upper Bound: 19.0810\n",
      "Prediction: 16.9069, Lower Bound: 14.8652, Upper Bound: 18.9486\n",
      "Prediction: 16.9972, Lower Bound: 14.9556, Upper Bound: 19.0389\n",
      "Prediction: 16.8597, Lower Bound: 14.8180, Upper Bound: 18.9013\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.8760, Lower Bound: 14.8375, Upper Bound: 18.9146\n",
      "Prediction: 17.0382, Lower Bound: 14.9966, Upper Bound: 19.0799\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9972, Lower Bound: 14.9556, Upper Bound: 19.0389\n",
      "Prediction: 16.9729, Lower Bound: 14.9313, Upper Bound: 19.0146\n",
      "Prediction: 16.9107, Lower Bound: 14.8908, Upper Bound: 18.9306\n",
      "Prediction: 16.9763, Lower Bound: 14.9346, Upper Bound: 19.0179\n",
      "Prediction: 16.7571, Lower Bound: 14.7155, Upper Bound: 18.7988\n",
      "Prediction: 17.4373, Lower Bound: 15.5866, Upper Bound: 19.2879\n",
      "Prediction: 17.0517, Lower Bound: 15.0100, Upper Bound: 19.0933\n",
      "Prediction: 17.0394, Lower Bound: 14.9977, Upper Bound: 19.0810\n",
      "Prediction: 16.9455, Lower Bound: 14.9039, Upper Bound: 18.9872\n",
      "Prediction: 16.9409, Lower Bound: 14.8996, Upper Bound: 18.9822\n",
      "Prediction: 16.8612, Lower Bound: 14.8861, Upper Bound: 18.8363\n",
      "Prediction: 16.8250, Lower Bound: 14.7833, Upper Bound: 18.8667\n",
      "Prediction: 17.0555, Lower Bound: 15.0140, Upper Bound: 19.0970\n",
      "Prediction: 16.7571, Lower Bound: 14.7155, Upper Bound: 18.7988\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 16.7945, Lower Bound: 14.7746, Upper Bound: 18.8145\n",
      "Prediction: 16.8250, Lower Bound: 14.7833, Upper Bound: 18.8667\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.8743, Lower Bound: 14.8326, Upper Bound: 18.9160\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.8822, Lower Bound: 14.8405, Upper Bound: 18.9239\n",
      "Prediction: 16.8998, Lower Bound: 14.8581, Upper Bound: 18.9415\n",
      "Prediction: 16.8821, Lower Bound: 14.8404, Upper Bound: 18.9238\n",
      "Prediction: 16.6383, Lower Bound: 14.6457, Upper Bound: 18.6309\n",
      "Prediction: 17.0462, Lower Bound: 15.0376, Upper Bound: 19.0549\n",
      "Prediction: 16.6693, Lower Bound: 14.6276, Upper Bound: 18.7110\n",
      "Prediction: 17.1424, Lower Bound: 15.1007, Upper Bound: 19.1840\n",
      "Prediction: 15.9770, Lower Bound: 14.1510, Upper Bound: 17.8029\n",
      "Prediction: 16.6266, Lower Bound: 14.5849, Upper Bound: 18.6682\n",
      "Prediction: 16.8564, Lower Bound: 14.8147, Upper Bound: 18.8981\n",
      "Prediction: 16.9080, Lower Bound: 14.8664, Upper Bound: 18.9497\n",
      "Prediction: 16.8282, Lower Bound: 14.7865, Upper Bound: 18.8699\n",
      "Prediction: 17.0179, Lower Bound: 14.9762, Upper Bound: 19.0596\n",
      "Prediction: 16.9987, Lower Bound: 14.9570, Upper Bound: 19.0404\n",
      "Prediction: 17.0284, Lower Bound: 14.9867, Upper Bound: 19.0701\n",
      "Prediction: 16.8821, Lower Bound: 14.8404, Upper Bound: 18.9238\n",
      "Prediction: 16.6842, Lower Bound: 14.6425, Upper Bound: 18.7259\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.7301, Lower Bound: 14.6885, Upper Bound: 18.7718\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8791, Lower Bound: 14.8374, Upper Bound: 18.9208\n",
      "Prediction: 16.8489, Lower Bound: 14.8072, Upper Bound: 18.8906\n",
      "Prediction: 16.8987, Lower Bound: 14.8570, Upper Bound: 18.9403\n",
      "Prediction: 16.9920, Lower Bound: 14.9503, Upper Bound: 19.0337\n",
      "Prediction: 16.8903, Lower Bound: 14.8486, Upper Bound: 18.9320\n",
      "Prediction: 17.0919, Lower Bound: 15.0502, Upper Bound: 19.1335\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 16.9771, Lower Bound: 14.9355, Upper Bound: 19.0188\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.8178, Lower Bound: 14.7793, Upper Bound: 18.8563\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.9921, Lower Bound: 14.9504, Upper Bound: 19.0338\n",
      "Prediction: 17.0618, Lower Bound: 15.0531, Upper Bound: 19.0704\n",
      "Prediction: 16.9985, Lower Bound: 14.9569, Upper Bound: 19.0402\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.8330, Lower Bound: 14.7913, Upper Bound: 18.8747\n",
      "Prediction: 17.8435, Lower Bound: 15.8019, Upper Bound: 19.8852\n",
      "Prediction: 16.9265, Lower Bound: 14.8891, Upper Bound: 18.9638\n",
      "Prediction: 16.9875, Lower Bound: 14.9460, Upper Bound: 19.0291\n",
      "Prediction: 16.7526, Lower Bound: 14.7109, Upper Bound: 18.7943\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.0949, Lower Bound: 15.0533, Upper Bound: 19.1366\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.7568, Lower Bound: 14.7368, Upper Bound: 18.7767\n",
      "Prediction: 16.7803, Lower Bound: 14.7387, Upper Bound: 18.8220\n",
      "Prediction: 16.9648, Lower Bound: 14.9231, Upper Bound: 19.0064\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.7645, Lower Bound: 14.7228, Upper Bound: 18.8061\n",
      "Prediction: 16.9431, Lower Bound: 14.9014, Upper Bound: 18.9847\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 17.0578, Lower Bound: 15.0204, Upper Bound: 19.0951\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.7476, Lower Bound: 14.7059, Upper Bound: 18.7893\n",
      "Prediction: 16.8863, Lower Bound: 14.8446, Upper Bound: 18.9279\n",
      "Prediction: 16.8202, Lower Bound: 14.7785, Upper Bound: 18.8619\n",
      "Prediction: 16.7791, Lower Bound: 14.7374, Upper Bound: 18.8208\n",
      "Prediction: 16.7581, Lower Bound: 14.7164, Upper Bound: 18.7998\n",
      "Prediction: 16.7292, Lower Bound: 14.6875, Upper Bound: 18.7709\n",
      "Prediction: 16.7674, Lower Bound: 14.7258, Upper Bound: 18.8091\n",
      "Prediction: 16.8657, Lower Bound: 14.8571, Upper Bound: 18.8744\n",
      "Prediction: 16.3806, Lower Bound: 14.5934, Upper Bound: 18.1678\n",
      "Prediction: 16.9872, Lower Bound: 14.9456, Upper Bound: 19.0288\n",
      "Prediction: 17.0101, Lower Bound: 15.1594, Upper Bound: 18.8608\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 16.9972, Lower Bound: 14.9556, Upper Bound: 19.0389\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.1375, Lower Bound: 15.1228, Upper Bound: 19.1522\n",
      "Prediction: 16.9682, Lower Bound: 14.9265, Upper Bound: 19.0099\n",
      "Prediction: 16.9870, Lower Bound: 14.9453, Upper Bound: 19.0287\n",
      "Prediction: 16.9645, Lower Bound: 14.9228, Upper Bound: 19.0062\n",
      "Prediction: 17.1598, Lower Bound: 15.1450, Upper Bound: 19.1746\n",
      "Prediction: 16.9442, Lower Bound: 14.9026, Upper Bound: 18.9859\n",
      "Prediction: 16.9326, Lower Bound: 14.8909, Upper Bound: 18.9743\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 16.9429, Lower Bound: 14.9013, Upper Bound: 18.9846\n",
      "Prediction: 16.7489, Lower Bound: 14.7072, Upper Bound: 18.7906\n",
      "Prediction: 16.7734, Lower Bound: 14.7317, Upper Bound: 18.8151\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.3375, Lower Bound: 14.4868, Upper Bound: 18.1882\n",
      "Prediction: 16.9373, Lower Bound: 14.8957, Upper Bound: 18.9789\n",
      "Prediction: 16.8330, Lower Bound: 14.7913, Upper Bound: 18.8747\n",
      "Prediction: 16.9457, Lower Bound: 14.9042, Upper Bound: 18.9871\n",
      "Prediction: 16.7207, Lower Bound: 14.6790, Upper Bound: 18.7623\n",
      "Prediction: 16.9771, Lower Bound: 14.9355, Upper Bound: 19.0188\n",
      "Prediction: 17.0865, Lower Bound: 15.0448, Upper Bound: 19.1282\n",
      "Prediction: 16.8245, Lower Bound: 14.7833, Upper Bound: 18.8657\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.9082, Lower Bound: 14.8665, Upper Bound: 18.9499\n",
      "Prediction: 16.5921, Lower Bound: 14.5932, Upper Bound: 18.5910\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.0347, Lower Bound: 14.9930, Upper Bound: 19.0764\n",
      "Prediction: 17.6416, Lower Bound: 15.9060, Upper Bound: 19.3772\n",
      "Prediction: 16.8591, Lower Bound: 14.8175, Upper Bound: 18.9008\n",
      "Prediction: 16.8197, Lower Bound: 14.7780, Upper Bound: 18.8614\n",
      "Prediction: 17.0463, Lower Bound: 15.0377, Upper Bound: 19.0550\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.9970, Lower Bound: 14.9553, Upper Bound: 19.0386\n",
      "Prediction: 16.9230, Lower Bound: 14.8813, Upper Bound: 18.9647\n",
      "Prediction: 16.9059, Lower Bound: 14.8642, Upper Bound: 18.9475\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.6047, Lower Bound: 14.5630, Upper Bound: 18.6464\n",
      "Prediction: 17.0347, Lower Bound: 14.9930, Upper Bound: 19.0764\n",
      "Prediction: 16.9490, Lower Bound: 14.9074, Upper Bound: 18.9907\n",
      "Prediction: 17.1229, Lower Bound: 15.0812, Upper Bound: 19.1646\n",
      "Prediction: 16.9481, Lower Bound: 15.0986, Upper Bound: 18.7977\n",
      "Prediction: 16.8728, Lower Bound: 14.8311, Upper Bound: 18.9145\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.9963, Lower Bound: 14.9557, Upper Bound: 19.0369\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8115, Lower Bound: 14.7706, Upper Bound: 18.8524\n",
      "Prediction: 16.9531, Lower Bound: 14.9118, Upper Bound: 18.9945\n",
      "Prediction: 17.0681, Lower Bound: 15.2398, Upper Bound: 18.8964\n",
      "Prediction: 16.9754, Lower Bound: 14.9337, Upper Bound: 19.0170\n",
      "Prediction: 16.8328, Lower Bound: 14.7911, Upper Bound: 18.8745\n",
      "Prediction: 16.7874, Lower Bound: 14.7457, Upper Bound: 18.8291\n",
      "Prediction: 16.9763, Lower Bound: 14.9346, Upper Bound: 19.0179\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.1914, Lower Bound: 15.1497, Upper Bound: 19.2331\n",
      "Prediction: 17.0394, Lower Bound: 14.9977, Upper Bound: 19.0810\n",
      "Prediction: 16.8135, Lower Bound: 14.8105, Upper Bound: 18.8166\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 16.8277, Lower Bound: 14.7860, Upper Bound: 18.8694\n",
      "Prediction: 17.0022, Lower Bound: 14.9605, Upper Bound: 19.0439\n",
      "Prediction: 16.8397, Lower Bound: 14.7980, Upper Bound: 18.8814\n",
      "Prediction: 16.8643, Lower Bound: 14.8226, Upper Bound: 18.9059\n",
      "Prediction: 16.9287, Lower Bound: 14.8882, Upper Bound: 18.9691\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.8998, Lower Bound: 14.8581, Upper Bound: 18.9415\n",
      "Prediction: 17.8531, Lower Bound: 16.0659, Upper Bound: 19.6403\n",
      "Prediction: 16.7409, Lower Bound: 14.6992, Upper Bound: 18.7826\n",
      "Prediction: 16.7894, Lower Bound: 14.7477, Upper Bound: 18.8310\n",
      "Prediction: 17.1093, Lower Bound: 15.0677, Upper Bound: 19.1510\n",
      "Prediction: 16.8434, Lower Bound: 14.8017, Upper Bound: 18.8851\n",
      "Prediction: 16.8227, Lower Bound: 14.7812, Upper Bound: 18.8643\n",
      "Prediction: 16.8296, Lower Bound: 14.7880, Upper Bound: 18.8713\n",
      "Prediction: 16.9236, Lower Bound: 14.8820, Upper Bound: 18.9653\n",
      "Prediction: 16.5604, Lower Bound: 14.7097, Upper Bound: 18.4111\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n",
      "Prediction: 17.0865, Lower Bound: 15.0448, Upper Bound: 19.1282\n",
      "Prediction: 16.8288, Lower Bound: 14.7932, Upper Bound: 18.8643\n",
      "Prediction: 16.9844, Lower Bound: 14.9427, Upper Bound: 19.0260\n",
      "Prediction: 17.0173, Lower Bound: 14.9757, Upper Bound: 19.0589\n",
      "Prediction: 16.9983, Lower Bound: 14.9897, Upper Bound: 19.0070\n",
      "Prediction: 16.7026, Lower Bound: 14.6878, Upper Bound: 18.7174\n",
      "Prediction: 16.7301, Lower Bound: 14.6885, Upper Bound: 18.7718\n",
      "Prediction: 16.9337, Lower Bound: 14.8921, Upper Bound: 18.9754\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.7526, Lower Bound: 14.7109, Upper Bound: 18.7943\n",
      "Prediction: 16.9108, Lower Bound: 14.8691, Upper Bound: 18.9524\n",
      "Prediction: 16.7448, Lower Bound: 14.7036, Upper Bound: 18.7860\n",
      "Prediction: 16.9792, Lower Bound: 14.9375, Upper Bound: 19.0208\n",
      "Prediction: 16.8283, Lower Bound: 14.7875, Upper Bound: 18.8690\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 16.8175, Lower Bound: 14.7758, Upper Bound: 18.8592\n",
      "Prediction: 16.9984, Lower Bound: 14.9567, Upper Bound: 19.0400\n",
      "Prediction: 17.0996, Lower Bound: 16.9045, Upper Bound: 17.2947\n",
      "Prediction: 16.7874, Lower Bound: 14.7457, Upper Bound: 18.8291\n",
      "Prediction: 16.9763, Lower Bound: 14.9346, Upper Bound: 19.0179\n",
      "Prediction: 16.7629, Lower Bound: 14.7212, Upper Bound: 18.8045\n",
      "Prediction: 16.8125, Lower Bound: 14.7741, Upper Bound: 18.8510\n",
      "Prediction: 17.0563, Lower Bound: 15.0146, Upper Bound: 19.0980\n",
      "Prediction: 16.8434, Lower Bound: 14.8017, Upper Bound: 18.8851\n",
      "Prediction: 16.6128, Lower Bound: 14.5770, Upper Bound: 18.6486\n",
      "Prediction: 16.6016, Lower Bound: 16.4633, Upper Bound: 16.7399\n",
      "Prediction: 16.9449, Lower Bound: 14.9032, Upper Bound: 18.9866\n"
     ]
    }
   ],
   "source": [
    "#Calculate residuals\n",
    "train_residuals = train_y3 - train_preds\n",
    "\n",
    "#Define the kernel for GPR\n",
    "kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0,(1e-4, 1e1))\n",
    "\n",
    "#Train the GPR model on residuals\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-2)\n",
    "gpr.fit(train_X3, train_residuals)\n",
    "\n",
    "#Make predictions on test set with GPR\n",
    "gpr_mean, gpr_std = gpr.predict(test_X3, return_std=True)\n",
    "\n",
    "#Combine GBR with GPR uncertainty\n",
    "final_preds = test_preds + gpr_mean\n",
    "\n",
    "#Calculate 95% confidence intervals\n",
    "#95% of data falls within 1.96 SD of the mean, so that standard is used to calculate confidence intervals\n",
    "lower_bound = final_preds - 1.96 * gpr_std\n",
    "upper_bound = final_preds + 1.96 * gpr_std\n",
    "\n",
    "#Print the results\n",
    "for i, (pred, lower, upper) in enumerate(zip(final_preds, lower_bound, upper_bound)):\n",
    "    print(f\"Prediction: {pred:.4f}, Lower Bound: {lower:.4f}, Upper Bound: {upper:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4ce32-a98c-4e4a-b695-9e407a6d6f0d",
   "metadata": {},
   "source": [
    "# Export the models\n",
    "\n",
    "Since we are utilizing Gaussian Processes, we have to export both the Gradient Boosting Regressor model and the Gaussian Process model for deployment in the User Interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64d4d1e-ac59-477b-9d70-c6330fc04021",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gbr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('gpr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gpr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d7d1805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleaned_data', 'feature_3.csv', 'X_train_3.csv', 'X_test_3.csv', '.DS_Store', 'merged_dataset', '1-- Import and Clean Initial Data-checkpoint.ipynb', 'weather_data.csv', 'gbr_x3_model.pkl', '3-- Descriptive Statistics and Visualizations-checkpoint.ipynb', 'gpr_model.pkl', 'Production.csv', '4 -- Feature Selection & Preprocessing-checkpoint.ipynb', 'feature_10.csv', '6-- Hyperparamter Tuning & Gaussian Processes.ipynb', 'static', 'preprocessing_pipeline.pkl', 'y_train_3.csv', 'y_test_3.csv', 'templates', '.ipynb_checkpoints', 'Production.numbers', '5 -- Initial Model Training and Evaluation.ipynb', 'web_model.py', 'myenv', 'gbr_model.pkl', '2-- Add Weather Data-checkpoint.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(os.getcwd()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
